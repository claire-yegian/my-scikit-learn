{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import random\n",
    "\n",
    "import mysklearn.myutils as myutils\n",
    "import mysklearn.plotutils as plotutils\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myclassifiers as myclassifiers\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MyNaiveBayesClassifier\n",
    "\n",
    "import mysklearn.myevaluation as myevaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: \n",
    "We chose to clean and classify Kaggle's Spotify dataset in order to evaluate our classifiers and learn about the predictive power of the attributes measured in the dataset. Initially, we had hoped to use environmental data (oil spills, carbon emissions, or electric vehicles), but we had a hard time finding a useable dataset. Particularly with electric vehicle data, we tried joining income, population, and demographic sets, hoping to come up with something with enough predictive power to build a classifier on. Ulitmately, we decided that our energy would be better spent on a more useable dataset, and we landed on the Spotify dataset. It has 21 attributes, one of which is popularity. We thought it would be interesting to use attributes like danceability, energy, and tempo to try and predict the popularity of the songs included in the dataset. \n",
    "\n",
    "Our classifiers did not end up performing very well on our data, which we can credit to the fact that none of the attributes had a correlation with popularity higher than 0.20 (correlation coefficient). Although all of the three classifiers we used–naive bayes, k nearest neighbors, and random forest–performed poorly, the random forrest classifier performed the best (accuracy: 39%, F1: 51%), while naive bayes followed closely behind (accuracy: 39%, F1: 39%), and k nearest neighbors performed the worst (accuracy: 27%, F1: 35%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 114000\n",
      "attribute           minimum    maximum       mid          avg      median\n",
      "----------------  ---------  ---------  --------  -----------  ----------\n",
      "popularity            0        100       50        33.2385      35\n",
      "danceability          0          0.985    0.4925    0.5668       0.58\n",
      "energy                0          1        0.5       0.641383     0.685\n",
      "loudness            -49.531      4.532  -22.4995   -8.25896     -7.004\n",
      "speechiness           0          0.965    0.4825    0.0846521    0.0489\n",
      "acousticness          0          0.996    0.498     0.31491      0.169\n",
      "instrumentalness      0          1        0.5       0.15605      4.16e-05\n",
      "liveness              0          1        0.5       0.213553     0.132\n",
      "valence               0          0.995    0.4975    0.474068     0.464\n",
      "tempo                 0        243.372  121.686   122.148      122.017\n"
     ]
    }
   ],
   "source": [
    "spotify_table = MyPyTable()\n",
    "spotify_table.load_from_file(\"./input_data/spotify_tracks.csv\")\n",
    "print(\"Number of instances:\", len(spotify_table.data))\n",
    "summary_stats = spotify_table.compute_summary_statistics([\"popularity\", \"danceability\", \"energy\", \"loudness\", \"speechiness\", \\\n",
    "    \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\"])\n",
    "summary_stats.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis: \n",
    "\n",
    "The Spotify dataset has 21 attributes including song identifiers (name, artists, track id), sound measures (acousticness, instrumentalness, speechiness), and energy measures (danceability, loudness, tempo). It originally had 114,000 instances, most of which had very low popularities (with a large portion of the data having a popularity of 0, low average of 33). Speechiness had a low average, suggesting that the data was skewed and not many songs had high measures of speechiness. Danceability, energy, valence, and tempo all had fairly even distributions (see summary statistics above), while speechiness, acousticness, instrumentalness, and liveness were a bit skewed. Many of the attributes were measured on a scale of 0 to 1, and all continuous attributes had to be discretized later on in order to be used in the random forest classifier. \n",
    "\n",
    "As we began our data cleaning, we started by removing all of the very high speechiness instances. Many of these were podcasts or recorded stories, and we didn't want that to impact our classifiers, which we intended to base on songs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_remove = []\n",
    "genre_row = spotify_table.get_column(\"track_genre\")\n",
    "genres = myutils.get_unique_values(genre_row)\n",
    "print(genres)\n",
    "for i in range(len(spotify_table.data)):\n",
    "    if spotify_table.data[i][spotify_table.column_names.index(\"speechiness\")] >= 0.85 and spotify_table.data[i][-1] in [\"kids\", \"children\", \"comedy\"]:\n",
    "        rows_to_remove.append(i)\n",
    "spotify_table.drop_rows(rows_to_remove)\n",
    "print(\"number of instances with stories removed:\", len(spotify_table.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we removed all duplicates. When we initally looked closely at our data, we noticed that some tracks appeared multiple times under different ablums or just as pure duplicates. Luckily all duplicate tracks had the same track identifier, so it was easy to find and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_remove = []\n",
    "track_ids = []\n",
    "for i in range(len(spotify_table.data)):\n",
    "    if spotify_table.data[i][1] not in track_ids:\n",
    "        track_ids.append(spotify_table.data[i][1])\n",
    "    else:\n",
    "        rows_to_remove.append(i)\n",
    "spotify_table.drop_rows(rows_to_remove)\n",
    "print(\"Number of instances with duplicates removed:\", len(spotify_table.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we chose the 10,000 most popular remaining songs. We wanted to avoid the skew of so many low-popularity songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_index_list = []\n",
    "popularity_column = spotify_table.get_column(\"popularity\")\n",
    "for i in range(len(popularity_column)):\n",
    "    popularity_index_list.append([popularity_column[i], i])\n",
    "popularity_index_list = sorted(popularity_index_list)\n",
    "\n",
    "rows_to_remove = [instance[1] for instance in popularity_index_list]\n",
    "rows_to_remove = rows_to_remove[:(len(popularity_index_list) - 10000)]\n",
    "spotify_table.drop_rows(rows_to_remove)\n",
    "print(\"Final number of instances:\", len(spotify_table.data))\n",
    "print(spotify_table.data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mysklearn.mypytable.MyPyTable at 0x7fbf9019da00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify_table = MyPyTable()\n",
    "spotify_table.load_from_file(\"./input_data/cleaned_spotify_tracks.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we narrowed our data down to the 10,000 most ppular songs, we looked at the ways it needed to be cleaned before classification. Track_genre was the only column that seemed to need cleaning, so we tried a few ways to clean track_genre to make it useable for the classifiers. There were so many unique values and some had so many more instances than others that it was difficult to find a logical way to regroup them while maintaining a reasonable distribution. Ultimately, we decided that track_genre probably wouldn't even be a good enough predictor for it to be worth the effort it would take to properly clean the data.\n",
    "\n",
    "We ran our knn classifier on our 10,000 instance dataset, and it took about 30 minutes to come up with a model. Because it took so long with so many instances, we decided to cut our data down to only 1,000 instances using random sampling. We then got rid of the index column and the track id column because they no longer added any information to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artists', 'album_name', 'track_name', 'popularity', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'track_genre'] [['Deftones', 'Saturday Night Wrist', 'Cherry Waves', 75.0, 317706.0, 'False', 0.47, 0.859, 2.0, -3.663, 1.0, 0.0537, 0.000362, 0.00691, 0.142, 0.17, 124.01, 4.0, 'metal'], ['Bethel Music;Kristene DiMarco', 'You Make Me Brave (Live)', 'It Is Well - Live', 62.0, 385053.0, 'False', 0.35, 0.25, 4.0, -10.648, 0.0, 0.0314, 0.698, 1.46e-05, 0.11, 0.11, 129.82, 4.0, 'ambient'], ['Dominic Fike;Zendaya', 'Elliot\\'s Song (From \"Euphoria\" An HBO Original Series)', 'Elliot\\'s Song - From \"Euphoria\" An HBO Original Series', 70.0, 150320.0, 'False', 0.394, 0.327, 4.0, -14.291, 1.0, 0.114, 0.849, 0.0, 0.125, 0.411, 93.358, 4.0, 'alt-rock'], ['Disturbed', 'Unstoppable', 'Unstoppable', 68.0, 238109.0, 'False', 0.529, 0.988, 1.0, -1.914, 1.0, 0.0768, 7.15e-06, 0.0278, 0.336, 0.336, 121.0, 4.0, 'metal'], ['Gracie Abrams', 'Difficult', 'Difficult', 72.0, 257881.0, 'False', 0.599, 0.59, 2.0, -9.135, 1.0, 0.0645, 0.432, 6.54e-06, 0.397, 0.402, 146.022, 4.0, 'indie-pop'], ['Keala Settle;The Greatest Showman Ensemble', 'This Is Me', 'This Is Me', 66.0, 234706.0, 'False', 0.284, 0.704, 2.0, -7.276, 1.0, 0.186, 0.00583, 0.000115, 0.0424, 0.1, 191.702, 4.0, 'show-tunes'], ['BTS', 'Proof', 'I NEED U', 63.0, 210986.0, 'False', 0.482, 0.858, 5.0, -4.169, 0.0, 0.069, 0.0218, 0.0, 0.244, 0.737, 158.075, 4.0, 'k-pop'], ['Fousheé', 'Deep End', 'Deep End', 69.0, 141223.0, 'True', 0.711, 0.592, 4.0, -7.136, 0.0, 0.23, 0.758, 0.0, 0.156, 0.535, 124.749, 4.0, 'indie'], ['Fly By Midnight', 'Silver Crane', 'Tomorrow', 64.0, 185474.0, 'False', 0.568, 0.669, 2.0, -5.698, 1.0, 0.037, 0.112, 0.0, 0.115, 0.405, 149.969, 4.0, 'electro'], ['Martin Garrix;Macklemore;Fall Out Boy', 'Summer Days (feat. Macklemore & Patrick Stump of Fall Out Boy)', 'Summer Days (feat. Macklemore & Patrick Stump of Fall Out Boy)', 74.0, 163804.0, 'True', 0.661, 0.723, 5.0, -6.976, 0.0, 0.0566, 0.179, 1.23e-05, 0.14, 0.316, 113.778, 4.0, 'dance']]\n"
     ]
    }
   ],
   "source": [
    "spotify_table.data = random.sample(spotify_table.data, k=1000)\n",
    "\n",
    "for i in range(len(spotify_table.data)):\n",
    "    spotify_table.data[i] = spotify_table.data[i][2:]\n",
    "spotify_table.column_names = spotify_table.column_names[2:]\n",
    "print(spotify_table.column_names, spotify_table.data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we had cut our data down to a more reasonable size, we saved it to a new file so we could easily reload it without running our whole datacleaning notebook again. We continued our EDA and classification in technical_report.ipynb so we didn't accidentally re-sample-and-clean our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_table.save_to_file(\"input_data/sampled_cleaned_spotify_tracks.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
